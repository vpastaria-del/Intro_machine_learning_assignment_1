{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ccce14-aa23-4714-9cae-1bcd18e08258",
   "metadata": {},
   "source": [
    "## Assignment 1 (50 marks)\n",
    "#### =====================================================================================================\n",
    "### Deadline: 09/14 11:59 pm\n",
    "#### ====================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d31af-2540-4440-b94f-a0539740f4b9",
   "metadata": {},
   "source": [
    "## Decision Tree Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1943b8d4",
   "metadata": {},
   "source": [
    "### Problem 1 (25 marks)\n",
    "\n",
    "`lab01_dataset_1.csv` contains a mixture of numerical and categorical data. Your task will be to write a function `my_ID3()` (without using the sklearn decision tree library) which can create a decision tree for the given dataset using the ID3 algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4d239a4",
   "metadata": {},
   "source": [
    "### 1.a (5 marks)\n",
    "\n",
    "ID3 cannot handle continuous numerical data. Perform the necessary operations to convert the continuous-valued attribute to boolean attributes (refer to page 40 of Decision Tree.pdf). Do not use any of the sklearn library for this task. Display the updated dataset after handling continuous-valued attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6753df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold used for Score: 69.0\n",
      "       Mood  Effort  Score Output  Score_high\n",
      "0     Happy     Low     35    Yes       False\n",
      "1     Happy  Medium     91     No        True\n",
      "2     Happy    High     52     No       False\n",
      "3   Neutral     Low     83     No        True\n",
      "4   Neutral  Medium     48     No       False\n",
      "5   Neutral    High     61     No       False\n",
      "6       Sad     Low     40    Yes       False\n",
      "7       Sad  Medium     98     No        True\n",
      "8       Sad    High     73    Yes        True\n",
      "9     Happy     Low     44    Yes       False\n",
      "10    Happy  Medium     86     No        True\n",
      "11    Happy    High     39    Yes       False\n",
      "12    Happy     Low     66     No       False\n",
      "13  Neutral  Medium     75    Yes        True\n",
      "14  Neutral    High     50     No       False\n",
      "15      Sad     Low     69     No       False\n",
      "16      Sad  Medium     70    Yes        True\n",
      "17      Sad    High     95     No        True\n",
      "18      Sad     Low     80    Yes        True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"lab01_dataset_1.csv\")\n",
    "threshold = df[\"Score\"].median() \n",
    "df[\"Score_high\"] = df[\"Score\"] > threshold\n",
    "print(\"Threshold used for Score:\", threshold)\n",
    "print(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7baf7d31",
   "metadata": {},
   "source": [
    "### 1.b (6 marks)\n",
    "\n",
    "Next, you will have to ensure that the newly obtained dataset is optimal and free of errors. Take appropriate actions based on the outcomes of the following steps:\n",
    "\n",
    "Check if the dataset has any missing values. (2 marks)<br>\n",
    "Check if the dataset has any redundant or repeated input sample. (2 marks)<br>\n",
    "Check if the dataset has any contradicting <input, output> pairs. (2 marks)\n",
    "\n",
    "Do note that you need to perform all the above steps programmatically and not simply by visual examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6104789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'threshold_used': np.float64(69.0), 'has_missing': np.False_, 'missing_counts': {'Mood': 0, 'Effort': 0, 'Score': 0, 'Output': 0, 'Score_high': 0}, 'num_redundant_samples': 0, 'redundant_examples': [], 'num_contradictions': 0, 'contradictions': {}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# (i) Missing values\n",
    "missing_counts = df.isnull().sum()\n",
    "has_missing = missing_counts.sum() > 0\n",
    "\n",
    "# (ii) Redundant / repeated input samples\n",
    "# Consider inputs = all columns except target (last column)\n",
    "target_col = df.columns[-1]\n",
    "input_cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "duplicates = df.duplicated(subset=input_cols, keep=False)\n",
    "redundant_samples = df[duplicates].sort_values(by=input_cols)\n",
    "\n",
    "# (iii) Contradicting <input, output> pairs\n",
    "# Find rows with same inputs but different outputs\n",
    "grouped = df.groupby(input_cols)[target_col].nunique()\n",
    "contradictions = grouped[grouped > 1]\n",
    "\n",
    "# Gather results\n",
    "results = {\n",
    "    \"threshold_used\": threshold,\n",
    "    \"has_missing\": has_missing,\n",
    "    \"missing_counts\": missing_counts.to_dict(),\n",
    "    \"num_redundant_samples\": int(duplicates.sum()),\n",
    "    \"redundant_examples\": redundant_samples.head(10).to_dict(orient=\"records\"),\n",
    "    \"num_contradictions\": int(contradictions.shape[0]),\n",
    "    \"contradictions\": contradictions.to_dict()\n",
    "}\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3a8a070",
   "metadata": {},
   "source": [
    "### 1.c (10 marks)\n",
    "\n",
    "Your function `my_ID3()` should operate in a manner such that after ever round of decision making, it will output the attributes and its associated gain, with a message stating “Attribute X with Gain = Y is chosen as the decision attribute”. You can obviously create other functions as needed for completing `my_ID3()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_ID3(dataset): # the input to the function is the final dataset you obtain after 1.b.\n",
    "    # iterate until decision tree is created.\n",
    "        # ID3 algorithm involves two mathematial computation.\n",
    "        # Entropy and Information Gain (check pages 12 to 15 of Decision Tree.pdf).\n",
    "        # Attributes with maximum Information Gain is chosen as decision nodes to split the data.\n",
    "        # Students should print out each decision nodes alongwith their respective Information Gain.\n",
    "    return decision_tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94c6b633-179b-4572-bec9-6a8e55801309",
   "metadata": {},
   "source": [
    "### 1.d (4 marks)\n",
    "\n",
    "Display the decision tree. The representation of the decision tree is upto you. You can choose either a textual representation or a graphical one; either is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dcc669-6c8d-463d-a494-8b6fb7e8b938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fa5fd65",
   "metadata": {},
   "source": [
    "### Problem 2 (25 marks)\n",
    "\n",
    "`lab01_dataset_2.csv` has a mixture of numerical and categorical data. For this problem, you will use sklearn's [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for the classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5855f31-3b64-4c32-98ad-830e31430758",
   "metadata": {},
   "source": [
    "### 2.a (5 marks)\n",
    "\n",
    "Encode all the categorial data into numerical data using `One-hot Encoding` and display the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ddd32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "538d2d0c",
   "metadata": {},
   "source": [
    "### 2.b (10 marks)\n",
    "\n",
    "Using the encoded dataset, perform the supervised learning using [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). Employ the [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) of 80-20 during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c15f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce9df279",
   "metadata": {},
   "source": [
    "### 2.c (5 marks)\n",
    "\n",
    "After the training is complete, show the results by predicting the class of the test set. Display the results of the prediction and test set side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f038e83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efe8c0ec",
   "metadata": {},
   "source": [
    "### 2.d (5 marks)\n",
    "\n",
    "Display the decision tree; it can be either a textual representation or a graphical representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0eed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
